import { GoogleGenAI } from '@google/genai';
import { KnowledgeBase } from '@shared/schema';
import { generateEmbedding, findSimilar } from './embeddings.js';
import { searchWeb } from './web-search.js';

const ai = new GoogleGenAI({ 
  apiKey: process.env.GEMINI_API_KEY 
});

// the newest Gemini model is "gemini-2.5-flash"
const MODEL = 'gemini-2.5-flash';

export async function generateAIResponse(
  userMessage: string,
  knowledgeEntries: KnowledgeBase[],
  config: { systemPrompt: string; fallbackMessage: string; maxTokens: number }
): Promise<string> {
  try {
    // PRIORIDADE 1: Sempre tentar usar OpenAI se tivermos conhecimento base
    if (knowledgeEntries.length > 0) {
      let context = '\n\nüìö Base de Conhecimento Dispon√≠vel:\n\n';
      
      // Tente usar semantic search se poss√≠vel
      let foundRelevant = false;
      try {
        const queryEmbedding = await generateEmbedding(userMessage);
        const knowledgeWithEmbeddings = knowledgeEntries
          .filter(kb => kb.embedding)
          .map(kb => ({
            id: kb.id,
            embedding: JSON.parse(kb.embedding!),
            subject: kb.subject,
            information: kb.information,
          }));

        const similarKnowledge = findSimilar(queryEmbedding, knowledgeWithEmbeddings, 0.4);
        
        if (similarKnowledge.length > 0) {
          foundRelevant = true;
          context = '\n\nüìö Informa√ß√µes Relevantes da Base de Conhecimento:\n\n';
          similarKnowledge.forEach((kb, index) => {
            context += `${index + 1}. **${kb.subject}** (${(kb.similarity * 100).toFixed(0)}% relevante):\n${kb.information}\n\n`;
          });
        } else {
          // Se n√£o encontrou similar, mostre todos
          knowledgeEntries.forEach((kb, index) => {
            context += `${index + 1}. **${kb.subject}**:\n${kb.information}\n\n`;
          });
        }
      } catch (embedError) {
        console.error('Erro ao gerar embedding:', embedError);
        // Fallback: use todos os conhecimentos sem semantic search
        knowledgeEntries.forEach((kb, index) => {
          context += `${index + 1}. **${kb.subject}**:\n${kb.information}\n\n`;
        });
      }

      // Tente usar Gemini com o contexto
      try {
        const systemMessage = `${config.systemPrompt}${context}

Baseando-se nas informa√ß√µes acima, responda a pergunta do usu√°rio de forma clara, √∫til e em portugu√™s.`;

        const response = await ai.models.generateContent({
          model: MODEL,
          config: {
            systemInstruction: systemMessage,
          },
          contents: userMessage,
        });

        return response.text || config.fallbackMessage;
      } catch (aiError: any) {
        console.error('Gemini indispon√≠vel, usando base de conhecimento direto:', aiError?.message);
        // OpenAI falhou, use a base de conhecimento como resposta direta
        const foundKnowledge = knowledgeEntries.filter(kb => 
          userMessage.toLowerCase().includes(kb.subject.toLowerCase()) ||
          kb.subject.toLowerCase().includes(userMessage.toLowerCase())
        );
        
        if (foundKnowledge.length > 0) {
          return `üìö Conforme nossa base de conhecimento sobre "${foundKnowledge[0].subject}":\n\n${foundKnowledge[0].information}`;
        }
        
        // Se n√£o encontrou match exato, mostre os 3 primeiros t√≥picos
        if (knowledgeEntries.length > 0) {
          return `N√£o encontrei exatamente sobre esse assunto, mas tenho informa√ß√µes sobre:\n\n${knowledgeEntries
            .slice(0, 3)
            .map(kb => `üìå **${kb.subject}**:\n${kb.information.substring(0, 200)}${kb.information.length > 200 ? '...' : ''}`)
            .join('\n\n')}`;
        }
        
        return config.fallbackMessage;
      }
    }

    // PRIORIDADE 2: Se n√£o temos conhecimento base, tente Gemini direto
    try {
      const response = await ai.models.generateContent({
        model: MODEL,
        config: {
          systemInstruction: config.systemPrompt,
        },
        contents: userMessage,
      });
      return response.text || config.fallbackMessage;
    } catch (error) {
      console.error('Gemini indispon√≠vel e sem base de conhecimento:', error);
      return "Estou tendo dificuldades para responder agora. Por favor, tente novamente em alguns momentos.";
    }
  } catch (error) {
    console.error('Erro cr√≠tico ao gerar resposta:', error);
    return "Desculpe, estou tendo dificuldades para responder no momento.";
  }
}

export async function analyzeSentiment(
  text: string
): Promise<{ sentiment: string; urgency: string; confidence: number }> {
  try {
    const response = await ai.models.generateContent({
      model: MODEL,
      config: {
        systemInstruction: `Voc√™ √© um especialista em an√°lise de sentimentos. Analise o sentimento e urg√™ncia de mensagens de suporte em portugu√™s.
Responda com JSON v√°lido neste formato exato:
{
  "sentiment": "positivo",
  "urgency": "alta",
  "confidence": 0.85
}

Diretrizes de urg√™ncia:
- alta: Cliente est√° frustrado, irritado ou enfrentando problemas cr√≠ticos
- m√©dia: Cliente precisa de ajuda mas est√° paciente
- baixa: Perguntas simples ou consultas gerais`,
        responseMimeType: 'application/json',
      },
      contents: text,
    });

    const text_response = response.text || '{}';
    const result = JSON.parse(text_response);
    
    // Map Portuguese to English for internal use
    const sentimentMap: { [key: string]: string } = {
      'positivo': 'positive',
      'neutro': 'neutral',
      'negativo': 'negative'
    };
    
    const urgencyMap: { [key: string]: string } = {
      'alta': 'high',
      'm√©dia': 'medium',
      'baixa': 'low'
    };
    
    return {
      sentiment: sentimentMap[result.sentiment] || 'neutral',
      urgency: urgencyMap[result.urgency] || 'medium',
      confidence: Math.max(0, Math.min(1, result.confidence || 0.5)),
    };
  } catch (error) {
    console.error('Erro ao analisar sentimento:', error);
    // Fallback: retorna valores padr√£o
    return {
      sentiment: 'neutral',
      urgency: 'medium',
      confidence: 0,
    };
  }
}
